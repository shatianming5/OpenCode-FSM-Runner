from __future__ import annotations

import json
from pathlib import Path

from .pipeline_verify import fmt_stage_tail
from .subprocess_utils import STDIO_TAIL_CHARS, tail
from .types import VerificationResult


def make_plan_update_prompt(snapshot_text: str, test_cmd: str, *, extra: str = "") -> str:
    extra = extra.strip()
    extra_block = f"\n[EXTRA]\n{extra}\n" if extra else ""
    return (
        "You are a strict plan editor. Your job: ONLY edit PLAN.md so it becomes machine-parseable and executable.\n"
        "\n"
        "Tooling:\n"
        "- To READ a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\"}\n"
        "  ```\n"
        "- To WRITE a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\", \"content\": \"...\"}\n"
        "  ```\n"
        "- To run a command, emit:\n"
        "  ```bash\n"
        "  bash\n"
        "  {\"command\":\"...\",\"description\":\"...\"}\n"
        "  ```\n"
        "Prefer file WRITE tool calls for any edits/creates (do NOT use bash redirections like `>` to write files).\n"
        "The runner executes tool calls and replies with a ```tool_result``` block.\n"
        "\n"
        "Hard constraints:\n"
        "1) You may ONLY modify PLAN.md. Do NOT touch any other file.\n"
        "2) Under `## Next (exactly ONE item)` there must be exactly ONE unchecked item:\n"
        "   `- [ ] (STEP_ID=NNN) ...`\n"
        "3) Each step must be atomic: one edit + one verification.\n"
        "4) Verification is ALWAYS the runner's TEST_CMD. Write steps so that after completing the step, running TEST_CMD will pass.\n"
        f"5) `## Acceptance` MUST include the exact line (verbatim): - [ ] TEST_CMD passes: `{test_cmd}`\n"
        "6) Do NOT put placeholders like `{TEST_CMD}` into PLAN.md; always use the exact TEST_CMD string.\n"
        "7) The `Next` item must be an IMPLEMENTATION step (edits code/scripts/config), not a meta planning step about editing PLAN.md.\n"
        "8) It is OK if the Next step creates new files; do not mark Blocked just to ask to 'add a file to chat'.\n"
        "9) Put uncertainty into `## Notes`. If you need human input, mark the step Blocked and specify what is needed.\n"
        "\n"
        f"TEST_CMD: {test_cmd}\n"
        "\n"
        f"{snapshot_text}"
        f"{extra_block}"
        "\n"
        "Now: edit PLAN.md only.\n"
    )


def make_execute_prompt(snapshot_text: str, step: dict[str, str]) -> str:
    return (
        "You are a strict executor. Your job: implement ONLY the single `Next` step.\n"
        "\n"
        "Tooling:\n"
        "- To READ a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\"}\n"
        "  ```\n"
        "- To WRITE a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\", \"content\": \"...\"}\n"
        "  ```\n"
        "- To run a command, emit:\n"
        "  ```bash\n"
        "  bash\n"
        "  {\"command\":\"...\",\"description\":\"...\"}\n"
        "  ```\n"
        "Prefer file WRITE tool calls for any edits/creates (do NOT use bash redirections like `>` to write files).\n"
        "The runner executes tool calls and replies with a ```tool_result``` block.\n"
        "\n"
        "Hard constraints:\n"
        "1) Do ONLY this one thing. No refactors, no extra features.\n"
        "2) Keep changes as small as possible.\n"
        "3) Do NOT modify PLAN.md.\n"
        "4) Do NOT modify the pipeline YAML (human-owned contract; runner will revert edits).\n"
        "5) You MAY create new files if needed; this run is unattended and file-create/add-to-chat prompts are auto-approved.\n"
        "\n"
        f"NEXT_STEP: (STEP_ID={step['id']}) {step['text']}\n"
        "\n"
        f"{snapshot_text}\n"
    )


def make_scaffold_contract_prompt(repo: Path, *, pipeline_rel: str, require_metrics: bool) -> str:
    required_keys = ["score"] if require_metrics else []
    required_line = ""
    if required_keys:
        required_line = f"- `.aider_fsm/metrics.json` must include keys: {required_keys}\n"
    return (
        "You are a contract scaffolder.\n"
        "\n"
        "Goal: make this repo runnable by the OpenCode-FSM runner in one command by creating a minimal, repo-local contract.\n"
        "Your output must be generic: do NOT embed repo-specific hardcoding unless it is explicitly present in the repo.\n"
        "\n"
        "IMPORTANT: `pipeline.yml` MUST follow the runner's v1 schema (top-level keys like: tests, deploy, rollout, benchmark, auth, "
        "evaluation, security, artifacts). Do NOT invent a custom schema (e.g. DO NOT write a top-level `stages:` list).\n"
        "\n"
        "Safety constraints for generated stage scripts:\n"
        "- Do NOT run dependency installs or network-heavy commands in stage scripts (no `pip install`, no `npm ci`, no `conda`, etc).\n"
        "- Do NOT run long workloads; keep stages bounded and unattended.\n"
        "- Prefer safe no-op stages (`echo not_configured; exit 0`) unless the repo explicitly provides runnable commands.\n"
        "\n"
        "Use this minimal skeleton (edit as needed):\n"
        "```yaml\n"
        "version: 1\n"
        "\n"
        "security:\n"
        "  mode: safe\n"
        "  max_cmd_seconds: 120\n"
        "  max_total_seconds: 600\n"
        "\n"
        "tests:\n"
        "  cmds:\n"
        "    - bash .aider_fsm/stages/tests.sh\n"
        "\n"
        "deploy:\n"
        "  setup_cmds:\n"
        "    - bash .aider_fsm/stages/deploy_setup.sh\n"
        "  health_cmds:\n"
        "    - bash .aider_fsm/stages/deploy_health.sh\n"
        "  teardown_policy: on_failure\n"
        "  teardown_cmds:\n"
        "    - bash .aider_fsm/stages/deploy_teardown.sh\n"
        "\n"
        "rollout:\n"
        "  run_cmds:\n"
        "    - bash .aider_fsm/stages/rollout.sh\n"
        "\n"
        "evaluation:\n"
        "  run_cmds:\n"
        "    - bash .aider_fsm/stages/evaluation.sh\n"
        "  metrics_path: .aider_fsm/metrics.json\n"
        "  required_keys: [score]\n"
        "\n"
        "benchmark:\n"
        "  run_cmds:\n"
        "    - bash .aider_fsm/stages/benchmark.sh\n"
        "\n"
        "artifacts:\n"
        "  out_dir: .aider_fsm/artifacts\n"
        "```\n"
        "\n"
        "Tooling:\n"
        "- To READ a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\"}\n"
        "  ```\n"
        "- To WRITE a file, emit:\n"
        "  ```json\n"
        "  {\"filePath\": \"PATH\", \"content\": \"...\"}\n"
        "  ```\n"
        "- To run a command, emit:\n"
        "  ```bash\n"
        "  bash\n"
        "  {\"command\":\"...\",\"description\":\"...\"}\n"
        "  ```\n"
        "Prefer file WRITE tool calls for any edits/creates (do NOT use bash redirections like `>` to write files).\n"
        "The runner executes tool calls and replies with a ```tool_result``` block.\n"
        "\n"
        "What to create/update:\n"
        f"- `{pipeline_rel}` (required; must be parseable YAML)\n"
        "- `.aider_fsm/stages/tests.sh`\n"
        "- `.aider_fsm/stages/deploy_setup.sh`\n"
        "- `.aider_fsm/stages/deploy_health.sh`\n"
        "- `.aider_fsm/stages/deploy_teardown.sh`\n"
        "- `.aider_fsm/stages/rollout.sh`\n"
        "- `.aider_fsm/stages/evaluation.sh`\n"
        "- `.aider_fsm/stages/benchmark.sh`\n"
        "- Optional: `.aider_fsm/bootstrap.yml` ONLY if the repo clearly documents deterministic, non-interactive setup.\n"
        "\n"
        "Two-tier behavior:\n"
        "A) Prefer REAL execution: if the repo clearly provides commands, wire them into the stage scripts.\n"
        "B) Otherwise SAFE no-op: stages may echo `not_configured` and exit 0, but evaluation MUST still write metrics.\n"
        "\n"
        "Hard constraints:\n"
        f"1) You may ONLY write `{pipeline_rel}` and files under `.aider_fsm/`.\n"
        "2) Do NOT modify application code or any other repo files.\n"
        "3) Keep everything non-interactive (assume unattended strict mode).\n"
        "4) Do NOT hardcode repo-specific names/ports/URLs/paths unless the repo already defines them.\n"
        "5) Prefer putting complex logic into `.aider_fsm/stages/*.sh`; keep `pipeline.yml` simple and stable.\n"
        "\n"
        "Discovery checklist (in this order):\n"
        "1) READ: README*, Makefile, pyproject.toml, requirements*.txt, package.json, docker-compose*.yml, .github/workflows/*\n"
        "2) Use `rg -n` to search for: test, pytest, npm test, make test, docker compose, benchmark, evaluate, rollout\n"
        "3) Only run lightweight commands when needed (e.g. `python -V`, `pytest --version`, `npm -v`, `make -n test`).\n"
        "4) Avoid long-running training; prefer bounded smoke commands if possible.\n"
        "\n"
        "Acceptance requirements:\n"
        "- `pipeline.yml` must be `version: 1`.\n"
        "- Evaluation must write a JSON object to `.aider_fsm/metrics.json`.\n"
        "- If evaluation is not configured, write: `{ \"score\": 0, \"note\": \"evaluation_not_configured\" }` (plus optional fields).\n"
        f"{required_line}"
        "\n"
        f"REPO_ROOT: {repo}\n"
        f"PIPELINE_PATH: {pipeline_rel}\n"
        "\n"
        "Now: inspect the repo and implement the contract.\n"
    )


def make_fix_or_replan_prompt(
    step: dict[str, str],
    verify: VerificationResult,
    *,
    tests_cmds: list[str],
    artifacts_dir: Path,
) -> str:
    metrics_errors = verify.metrics_errors or []
    metrics_block = ""
    if verify.metrics_path or metrics_errors:
        metrics_block = (
            "[METRICS]\n"
            f"metrics_path: {verify.metrics_path}\n"
            f"errors: {metrics_errors}\n"
            f"metrics_preview: {tail(json.dumps(verify.metrics or {}, ensure_ascii=False), 2000)}\n"
            "\n"
        )
    return (
        "Verification failed. You must choose exactly ONE:\n"
        "A) Fix code/scripts/manifests until verification passes (preferred).\n"
        "B) If it truly cannot be closed without missing info: ONLY edit PLAN.md to split the step or mark it Blocked.\n"
        "\n"
        f"FAILED_STEP: (STEP_ID={step['id']}) {step['text']}\n"
        "\n"
        f"FAILED_STAGE: {verify.failed_stage}\n"
        f"TEST_CMDS: {' && '.join(tests_cmds)}\n"
        f"ARTIFACTS_DIR: {artifacts_dir}\n"
        "\n"
        "You MAY create new files if needed; this run is unattended and file-create/add-to-chat prompts are auto-approved.\n"
        "\n"
        "If this is an environment/tooling/auth issue, you may write `.aider_fsm/actions.yml` for the runner to execute.\n"
        "actions.yml format (YAML):\n"
        "version: 1\n"
        "actions:\n"
        "- id: fix-001\n"
        "  kind: run_cmd\n"
        "  cmd: <shell command>\n"
        "  timeout_seconds: 300\n"
        "  retries: 0\n"
        "  risk_level: low|medium|high\n"
        "  rationale: <why>\n"
        "Notes:\n"
        "- In strict unattended mode, avoid interactive login commands (e.g. `docker login` without non-interactive flags).\n"
        "- Runner records artifacts and then deletes actions.yml.\n"
        "\n"
        f"{fmt_stage_tail('BOOTSTRAP', verify.bootstrap)}"
        f"{fmt_stage_tail('AUTH', verify.auth)}"
        f"{fmt_stage_tail('TESTS', verify.tests)}"
        f"{fmt_stage_tail('DEPLOY_SETUP', verify.deploy_setup)}"
        f"{fmt_stage_tail('DEPLOY_HEALTH', verify.deploy_health)}"
        f"{fmt_stage_tail('ROLLOUT', verify.rollout)}"
        f"{fmt_stage_tail('EVALUATION', verify.evaluation)}"
        f"{fmt_stage_tail('BENCHMARK', verify.benchmark)}"
        f"{metrics_block}"
    )


def make_mark_done_prompt(step: dict[str, str]) -> str:
    return (
        "This step passed verification. ONLY edit PLAN.md:\n"
        f"1) Move `- [ ] (STEP_ID={step['id']}) ...` from Next to Done, and change it to `- [x]`.\n"
        "2) Pick ONE smallest atomic unchecked item from Backlog into Next (keep Next to exactly one item).\n"
        "3) If Backlog is empty, leave Next empty (keep the heading, no items).\n"
    )


def make_block_step_prompt(step: dict[str, str], last_failure: str) -> str:
    return (
        "Fix attempts exceeded the limit. ONLY edit PLAN.md:\n"
        "1) Remove the step from Next; in Notes, explain why it's Blocked and what human input is needed.\n"
        "2) Pick one item from Backlog into Next (or leave Next empty).\n"
        "\n"
        f"BLOCKED_STEP: (STEP_ID={step['id']}) {step['text']}\n"
        "\n"
        "[LAST_FAILURE]\n"
        f"{tail(last_failure, STDIO_TAIL_CHARS)}\n"
    )
